{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import modules \n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lda\n",
    "from numpy import genfromtxt\n",
    "from nltk import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = genfromtxt('data/tdm.csv', delimiter=',',\n",
    "                  skip_header=1, dtype=np.int64)\n",
    "\n",
    "words = genfromtxt('data/tdm.csv', delimiter=',',\n",
    "                  skip_header=0, dtype=np.str_)\n",
    "words=words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA instance at 0x7f0a2975d7e8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model LDA\n",
    "\n",
    "model = lda.LDA(n_topics=20, n_iter=500, random_state=1)\n",
    "model.fit(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: euro area banknot currenc bank coin countri changeov\n",
      "Topic 1: global intern economi financi emerg world import globalis\n",
      "Topic 2: euro area countri competit state econom inflat unit\n",
      "Topic 3: market integr financi euro european area secur singl\n",
      "Topic 4: polici area euro fiscal countri govern monetari economi\n",
      "Topic 5: question think say said time bank thank come\n",
      "Topic 6: bank central institut system supervisori level framework nation\n",
      "Topic 7: polici see economi econom paper rate shock work\n",
      "Topic 8: asset price risk effect invest market increas low\n",
      "Topic 9: price inflat euro growth area expect remain econom\n",
      "Topic 10: countri bank central exchang intern access role process\n",
      "Topic 11: rate govern council polici growth monetari exchang develop\n",
      "Topic 12: inflat central bank monetari polici expect decis strategi\n",
      "Topic 13: growth product labour reform market structur increas employ\n",
      "Topic 14: financi risk system market crisi stabil institut sector\n",
      "Topic 15: statist area data euro inform european confer monetari\n",
      "Topic 16: bank market liquid rate credit oper measur financi\n",
      "Topic 17: european europ union member new currenc state euro\n",
      "Topic 18: import time let year stabil need challeng new\n",
      "Topic 19: polici monetari price stabil euro econom area maintain\n"
     ]
    }
   ],
   "source": [
    "# Most frequent words in every topic\n",
    "vocab=words\n",
    "topic_word = model.topic_word_  \n",
    "n_top_words = 9\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SAVE LDA SCORES \n",
    "np.savetxt(\"data/LDA.csv\", model.doc_topic_, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import dictionary from excel file\n",
    "df = pd.read_excel(\"data/LoughranMcDonald_MasterDictionary_2014.xlsx\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tokens = [str(x).lower() for x in df['Word']]\n",
    "tokens=[PorterStemmer().stem(t) for t in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GetDictScore(data, dictionary, words):\n",
    "    \n",
    "    score=[0 for o in range(len(data))]\n",
    "    for i in range(len(words)):\n",
    "        try:\n",
    "            value=int(dictionary[words[i]])\n",
    "            if value>0:\n",
    "                for j in range(len(data)):\n",
    "                    score[j]=score[j]+value*data[j][i]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DictScores=[]\n",
    "\n",
    "dictionaries=[\"Negative\", \"Positive\", \"Uncertainty\", \"Litigious\", \"Constraining\", \"Superfluous\",\"Interesting\", \"Harvard_IV\"]\n",
    "\n",
    "\n",
    "for d in dictionaries:\n",
    "    score = [str(x).lower() for x in df[d]] # or any other method\n",
    "    dictionary=dict(zip(tokens,score))\n",
    "    score=GetDictScore(data,dictionary,words)\n",
    "    DictScores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myfile = open(\"data/Dictionary_Scores.csv\", 'w')\n",
    "wr = csv.writer(myfile)\n",
    "wr.writerows(DictScores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF WITH CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copute tf-idf using corpus as input\n",
    "# initialize\n",
    "corpus=[]\n",
    "with open('data/tdm.csv', 'rb') as csvfile:\n",
    "    data = csv.reader(csvfile)\n",
    "    for row in data:\n",
    "        corpus.append(row)\n",
    "del corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF(D,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute TF(DV)\n",
    "tf=[]\n",
    "for i in range(len(corpus)):\n",
    "    scores=[]\n",
    "    for num in corpus[i]:\n",
    "        if int(num)==0:\n",
    "            value=0\n",
    "        else:\n",
    "            value=1+math.log(float(num))\n",
    "            \n",
    "        scores.append(value)\n",
    "    tf.append(scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### idf(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute idf(v)\n",
    "\n",
    "idf=[0]*len(corpus[0])\n",
    "\n",
    "for v in range(len(corpus[0])):\n",
    "    score=0\n",
    "    for d in range(len(corpus)):\n",
    "        if int(corpus[d][v])>0:\n",
    "            score=score+1\n",
    "    idf[v]=score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute tf-idf using the previous tf and idf\n",
    "\n",
    "tf_idf=tf\n",
    "\n",
    "for d in range(len(corpus)):\n",
    "    for v in range(len(corpus[0])):\n",
    "        tf_idf[d][v]=tf[d][v]*idf[v]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myfile = open(\"data/TF_IDF.csv\", 'wb')\n",
    "wr = csv.writer(myfile)\n",
    "wr.writerows(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute dictinary scores with tf-idf input\n",
    "tfidf = genfromtxt(\"data/TF_IDF.csv\", delimiter=',',\n",
    "                   skip_footer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DictScores=[]\n",
    "\n",
    "dictionaries=[\"Negative\", \"Positive\", \"Uncertainty\", \"Litigious\", \"Constraining\", \"Superfluous\",\"Interesting\", \"Harvard_IV\"]\n",
    "\n",
    "\n",
    "for d in dictionaries:\n",
    "    score = [str(x).lower() for x in df[d]] # or any other method\n",
    "    dictionary=dict(zip(tokens,score))\n",
    "    score=GetDictScore(tfidf,dictionary,words)\n",
    "    DictScores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "myfile = open(\"data/Dictionary_Scores_tfidf.csv\", 'wb')\n",
    "wr = csv.writer(myfile)\n",
    "wr.writerows(DictScores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
