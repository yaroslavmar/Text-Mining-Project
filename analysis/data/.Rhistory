ep1
tp1
v1<-ep1[i]*tp1[1]*sum(alpha[1]+tp2[1]*alpha[2]+tp3[1]*alpha[3])
v1
v2<-ep1[i]*sum(tp1[2]*alpha[1]+tp2[2]*alpha[2]+tp3[2]*alpha[3])
v2
v1<-ep1[i]*sum(tp1[1]*alpha[1]+tp2[1]*alpha[2]+tp3[1]*alpha[3])
v2<-ep2[i]*sum(tp1[2]*alpha[1]+tp2[2]*alpha[2]+tp3[2]*alpha[3])
v3<-ep3[i]*sum(tp1[3]*alpha[1]+tp2[3]*alpha[2]+tp3[3]*alpha[3])
i
i<-1
v1<-ep1[i]*sum(tp1[1]*alpha[1]+tp2[1]*alpha[2]+tp3[1]*alpha[3])
v2<-ep2[i]*sum(tp1[2]*alpha[1]+tp2[2]*alpha[2]+tp3[2]*alpha[3])
v3<-ep3[i]*sum(tp1[3]*alpha[1]+tp2[3]*alpha[2]+tp3[3]*alpha[3])
v1
v2
v3
cs<-state[3500]
cpred<-rep(NA,23)
for(i in 1:23){
v1<-ep1[i]*sum(tp1[1]*alpha[1]+tp2[1]*alpha[2]+tp3[1]*alpha[3])
v2<-ep2[i]*sum(tp1[2]*alpha[1]+tp2[2]*alpha[2]+tp3[2]*alpha[3])
v3<-ep3[i]*sum(tp1[3]*alpha[1]+tp2[3]*alpha[2]+tp3[3]*alpha[3])
pred[i]<-(v1+v2+v3)/PX
#pred[i]<-((ep1[i]+ep2[i]+ep3[i])* sum(alpha[1]*tp1+ alpha[2]*tp2+ alpha[3]*tp3))/PX
}
pred
sum(pred)
breathdata <- read.csv("~/BGSE/Master Project/data/breathdata/breathdata.csv", sep=";")
event<-breathdata$Ineff_Effort>45
event[is.na(event)]<-FALSE
group<-c()
date<-c()
for(i in 1:3500){  #3500
group<-c(group,rep(i,50)) #50
date_n<-breathdata$Time[i*50]
date[i]<-as.character(date_n[1])
}
date<-strptime(date,  "%Y-%m-%d %H:%M:%OS")
group<-group[1:length(event)]
events<-tapply(event,group, sum)
library(depmixS4)
y<-as.factor(events)
levels(y)<-as.character(seq(0,50,1))
set.seed(2016)
mod <- depmix(y~1,
family=multinomial("identity"),
nstates = 3, ntimes = length(events))
fm <- fit(mod)
post<-posterior(fm)
col3<-ifelse(post$state==1, "yellow", ifelse(post$state==3, "darkorange", "black"))
plot(date,y, t="h",cex=0.2, col=col3,
main="# Ineff Eff per cada 50 respiracions",
ylab="")
grid()
cex=1.5, col=c("black","yellow", "orange"), pch=16)
dev.off()
fb<-forwardbackward(fm)
a<-fb$alpha[3500,]
b<-fb$beta[3500,]
PX<-sum(a*b)
ep1<-fm@response[[1]][[1]]@parameters$coefficients
ep2<-fm@response[[2]][[1]]@parameters$coefficients
ep3<-fm@response[[3]][[1]]@parameters$coefficients
tp1<-fm@transition[[1]]@parameters[[1]] ; tp1
tp2<-fm@transition[[2]]@parameters[[1]]
tp3<-fm@transition[[3]]@parameters[[1]]
alpha<-fb$alpha[3500,]
cs<-state[3500]
cpred<-rep(NA,23)
for(i in 1:23){
v1<-ep1[i]*sum(tp1[1]*alpha[1]+tp2[1]*alpha[2]+tp3[1]*alpha[3])
v2<-ep2[i]*sum(tp1[2]*alpha[1]+tp2[2]*alpha[2]+tp3[2]*alpha[3])
v3<-ep3[i]*sum(tp1[3]*alpha[1]+tp2[3]*alpha[2]+tp3[3]*alpha[3])
pred[i]<-(v1+v2+v3) #/PX
#pred[i]<-((ep1[i]+ep2[i]+ep3[i])* sum(alpha[1]*tp1+ alpha[2]*tp2+ alpha[3]*tp3))/PX
}
pred<-rep(NA,23)
for(i in 1:23){
v1<-ep1[i]*sum(tp1[1]*alpha[1]+tp2[1]*alpha[2]+tp3[1]*alpha[3])
v2<-ep2[i]*sum(tp1[2]*alpha[1]+tp2[2]*alpha[2]+tp3[2]*alpha[3])
v3<-ep3[i]*sum(tp1[3]*alpha[1]+tp2[3]*alpha[2]+tp3[3]*alpha[3])
pred[i]<-(v1+v2+v3) #/PX
#pred[i]<-((ep1[i]+ep2[i]+ep3[i])* sum(alpha[1]*tp1+ alpha[2]*tp2+ alpha[3]*tp3))/PX
}
sum(pred)
plot(ep1, t="b", ylim=c(0,1), pch=16)
lines(ep2, col="darkred", t="b", pch=16)
lines(ep3, col="darkblue", t="b", pch=16)
lines(pred, col="orange", t="b", pch=16)
plot(date,y, t="h",cex=0.2, col=col3,
main="# Ineff Eff per cada 50 respiracions",
ylab="")
grid()
legend('topleft', c("Good","Intermediate", "Bad"),
cex=1.5, col=c("black","yellow", "orange"), pch=16)
plot(date,y, t="h",cex=0.2, col=col3,
main="# Ineff Eff per cada 50 respiracions",
ylab="")
grid()
pred
sum(pred)
pred*seq(1,23,1)
sum(pred*seq(1,23,1))
breathdata <- read.csv("~/BGSE/Master Project/data/breathdata/breathdata.csv", sep=";")
event<-breathdata$Ineff_Effort
event[is.na(event)]<-0
library(depmixS4)
summary(event)
?depmix
hist(event)
hist(event, breaks=100)
hist(event, breaks=5)
mod <- depmix(event~1,
family=poisson("identity"),
nstates = 3, ntimes = length(events))
set.seed(2016)
mod <- depmix(event~1,
family=poisson("identity"),
nstates = 3, ntimes = length(event))
fm <- fit(mod)
plot(event,t="h")
set.seed(2016)
mod <- depmix(event~1,
family=poisson(),
nstates = 3, ntimes = length(event))
fm <- fit(mod)
set.seed(2016)
mod <- depmix(event~1,
family=gaussian(),
nstates = 3, ntimes = length(event))
fm <- fit(mod)
### IMPORT DATA
setwd("~/Dropbox/BGSE/3rd Term/Text Mining/Project/analysis")
# LDA topic allocation
lda<-read.csv("LDA.csv", header=FALSE)
#lda<-read.csv("LDA_crisis.csv", header=FALSE)
# Dictionary scores
dict<-read.csv("Dictionary_Scores.csv", header=FALSE)
dict<-t(dict)
dict<-apply(dict, 2, as.numeric)
dict<-scale(dict)
# TF-IDF weighting (last ommited)
tfidf<-read.csv("TF_IDF.csv", header=FALSE)
tfidf<-read.csv("Dictionary_Scores_tfidf.csv", header=FALSE)
tfidf<-t(tfidf)
tfidf<-scale(tfidf)
date<-read.csv("dates.csv", header=FALSE)
date<-t(date)[,1]
date<-as.Date(date, "%d/%m/%Y")
rp <- read.csv("Risk_Premium.csv", sep="")
country<-"ES"
GetTarget2<-function(data, country, date){
# spread
rp1<-data$values[rp$geo==country] - data$values[rp$geo=="DE"]
# date of risk premium
date1<-data[data$geo==country,3]
# combine spread and date in data.frame
X<-data.frame(time=date1, spread=rp1)
X$time<-as.Date(X$time, "%Y-%m-%d")
X<-X[X$time>"1998-01-1",]
# find index of dates
index<-rep(NA,length(date))
for( i in 1:length(index)){
if(date[i] %in% X$time){
ind<-which(X$time==date[i])
ind2<-which(!is.na(X$spread[ind:(ind+10)])==TRUE)[1]
#index[i]<-which(X$time==date[i])
index[i]<-ind+ind2-1
} else {
ind<-which(X$time %in% c(date[i]+1,date[i]+2, date[i]+3,date[i]+4, date[i]+5))[1]
ind2<-which(!is.na(X$spread[ind:(ind+10)])==TRUE)[1]
#index[i]<-which(X$time %in% c(date[i]+1,date[i]+2, date[i]+3,date[i]+4, date[i]+5))[1]
index[i]<-ind+ind2-1
}
}
# fill target
target<-rep(NA,length(date))
for( i in 1:length(target)){
target[i]<-X$spread[index[i]]
}
return(list(target=target, index=index, X=X))
}
country<-"IT"
GetTarget2<-function(data, country, date){
# spread
rp1<-data$values[rp$geo==country] - data$values[rp$geo=="DE"]
# date of risk premium
date1<-data[data$geo==country,3]
# combine spread and date in data.frame
X<-data.frame(time=date1, spread=rp1)
X$time<-as.Date(X$time, "%Y-%m-%d")
X<-X[X$time>"1998-01-1",]
# find index of dates
index<-rep(NA,length(date))
for( i in 1:length(index)){
if(date[i] %in% X$time){
ind<-which(X$time==date[i])
ind2<-which(!is.na(X$spread[ind:(ind+10)])==TRUE)[1]
#index[i]<-which(X$time==date[i])
index[i]<-ind+ind2-1
} else {
ind<-which(X$time %in% c(date[i]+1,date[i]+2, date[i]+3,date[i]+4, date[i]+5))[1]
ind2<-which(!is.na(X$spread[ind:(ind+10)])==TRUE)[1]
#index[i]<-which(X$time %in% c(date[i]+1,date[i]+2, date[i]+3,date[i]+4, date[i]+5))[1]
index[i]<-ind+ind2-1
}
}
# fill target
target<-rep(NA,length(date))
for( i in 1:length(target)){
target[i]<-X$spread[index[i]]
}
return(list(target=target, index=index, X=X))
}
Target<-GetTarget2(rp, "ES", date)
index<-Target$index
X<-Target$X
#year<-X$time[index]
#year<-as.numeric(format(year, format = "%Y"))
target<-Target$target
target<-target[-555]
target<-log(target+1)
# Data preparation
X<-cbind(lda, dict)
X<-X[-555,]
X<-cbind(X,tfidf)
#X$year<-year[-555]
#X$year<-as.factor(X$year)
#colnames(X)[8:15]<-paste("Dict_", 1:8, sep="")
dict_names<-c("Negative", "Positive", "Uncertainty", "Litigious", "Constraining", "Superfluous","Interesting", "Harvard_IV")
colnames(X)[8:15]<-dict_names
colnames(X)[16:23]<-paste("tfidf_", dict_names, sep="")
colnames(X)[1:7]<-paste("Topic_", 1:7, sep="")
# Model
model<-lm(target ~. , data=X[,-c(1,23)])
summary(model)
lda<-read.csv("LDA2.csv", header=FALSE)
dict<-read.csv("Dictionary_Scores.csv", header=FALSE)
dict<-t(dict)
dict<-apply(dict, 2, as.numeric)
dict<-scale(dict)
# TF-IDF weighting (last ommited)
tfidf<-read.csv("TF_IDF.csv", header=FALSE)
tfidf<-read.csv("Dictionary_Scores_tfidf.csv", header=FALSE)
tfidf<-t(tfidf)
tfidf<-scale(tfidf)
# Date of the speeches
date<-read.csv("dates.csv", header=FALSE)
date<-t(date)[,1]
date<-as.Date(date, "%d/%m/%Y")
#date_new<-date[400:555]
# Risk Premium
rp <- read.csv("Risk_Premium.csv", sep="")
country<-"ES"
# Compute Target
GetTarget2<-function(data, country, date){
# spread
rp1<-data$values[rp$geo==country] - data$values[rp$geo=="DE"]
# date of risk premium
date1<-data[data$geo==country,3]
# combine spread and date in data.frame
X<-data.frame(time=date1, spread=rp1)
X$time<-as.Date(X$time, "%Y-%m-%d")
X<-X[X$time>"1998-01-1",]
# find index of dates
index<-rep(NA,length(date))
for( i in 1:length(index)){
if(date[i] %in% X$time){
ind<-which(X$time==date[i])
ind2<-which(!is.na(X$spread[ind:(ind+10)])==TRUE)[1]
#index[i]<-which(X$time==date[i])
index[i]<-ind+ind2-1
} else {
ind<-which(X$time %in% c(date[i]+1,date[i]+2, date[i]+3,date[i]+4, date[i]+5))[1]
ind2<-which(!is.na(X$spread[ind:(ind+10)])==TRUE)[1]
#index[i]<-which(X$time %in% c(date[i]+1,date[i]+2, date[i]+3,date[i]+4, date[i]+5))[1]
index[i]<-ind+ind2-1
}
}
# fill target
target<-rep(NA,length(date))
for( i in 1:length(target)){
target[i]<-X$spread[index[i]]
}
return(list(target=target, index=index, X=X))
}
Target<-GetTarget2(rp, "ES", date)
index<-Target$index
X<-Target$X
#year<-X$time[index]
#year<-as.numeric(format(year, format = "%Y"))
target<-Target$target
target<-target[-555]
target<-log(target+1)
X<-cbind(lda, dict)
X<-X[-555,]
X<-cbind(X,tfidf)
colnames(X)
colnames(X)[21:29]<-dict_names
length(dict_names)
length(dict_names)
colnames(X)
X<-cbind(lda, dict)
X<-X[-555,]
X<-cbind(X,tfidf)
#X$year<-year[-555]
#X$year<-as.factor(X$year)
#colnames(X)[8:15]<-paste("Dict_", 1:8, sep="")
dict_names<-c("Negative", "Positive", "Uncertainty", "Litigious", "Constraining", "Superfluous","Interesting", "Harvard_IV")
colnameS(X)
colnames(X)
colnames(X)[21:28]<-dict_names
colnames(X)[29:36]<-paste("tfidf_", dict_names, sep="")
colnames(X)[1:20]<-paste("Topic_", 1:20, sep="")
dim(X)
model<-lm(target ~. , data=X[,-c(1,36)])
summary(model)
summary(model)
library(MASS)
stepwise <- stepAIC(model, direction="both")
stepwise$anova # display results
model_step<-lm(target ~ Topic_5 + Topic_8 + Topic_9 + Topic_10 + Topic_11 +
Topic_12 + Topic_14 + Topic_17 + Topic_20 + Negative + Positive +
Uncertainty + Litigious + Constraining + Harvard_IV + tfidf_Uncertainty, data=X[,-c(1,36)])
summary(model_step)
summary(model)
summary(model_step)
library(leaps)
leaps<-regsubsets(target~. ,data=X[,-c(1,36)],nbest=1)
summary(leaps)
model_leaps<-lm(target ~ Topic_5 + Topic_10 + Topic_11 + Topic_14 + Topic_20 + Positive + tfidf_Negative +tfidf_Uncertainty, data=X[,-c(1,36)]
)
summary(model_leaps) #  8 variables
topic<-apply(lda,1,which.max)
topic_score<-apply(lda,1,max)
# find to which topic belogs the badass speech "I will do whatever it takes"
topic_top<-topic[483]
topic_top
for( i in 1:20){  #4
plot(date,lda[,i], t="h", main=paste("Topic",i), ylab="",xlab="",col="darkblue")
grid()
}
par(mfrow=c(3,2))
#layout(matrix(c(1,2,3,4,5,6,7,7), 4, 2, byrow = TRUE))
for( i in c(5,10,11,14,20)){
plot(date,lda[,i], t="h", main=paste("Topic",i), ylab="",xlab="",col="darkblue")
grid()
}
png("/home/yaroslav/Dropbox/BGSE/3rd Term/Text Mining/Project/document/lda_selected.png", width = 400, height = 400)
par(mfrow=c(3,2))
#layout(matrix(c(1,2,3,4,5,6,7,7), 4, 2, byrow = TRUE))
for( i in c(5,10,11,14,20)){
plot(date,lda[,i], t="h", main=paste("Topic",i), ylab="",xlab="",col="darkblue")
grid()
}
dev.off()
table(topic)
plot(date,target)
plot(date[-555],target)
par(mfrow=c(1,1))
plot(date[-555],target)
plot(date[-555],target, t="l")
plot(date[-555],target, t="b", col="topic")
plot(date[-555],target, t="b", col=topic)
plot(date[-555],target, t="h", col=topic)
setwd("~/Dropbox/BGSE/3rd Term/Text Mining/Project/analysis/data")
lda<-read.csv("LDA.csv", header=FALSE)
setwd("~/Projects/Text-Mining-Project/analysis")
setwd("~/Projects/Text-Mining-Project/analysis)
lda<-read.csv("LDA.csv", header=FALSE)
lda<-lda[-555,]
lda<-read.csv("LDA.csv", header=FALSE)
#setwd("~/Projects/Text-Mining-Project/analysis/data)
# LDA topic allocation
lda<-read.csv("LDA.csv", header=FALSE)
setwd("~/Projects/Text-Mining-Project/analysis/data)
# LDA topic allocation
lda<-read.csv("LDA.csv", header=FALSE)
setwd("~/Projects/Text-Mining-Project/analysis/data")
lda<-read.csv("LDA.csv", header=FALSE)
lda<-lda[-555,]
dict<-read.csv("Dictionary_Scores.csv", header=FALSE)
dict<-t(dict)
dict<-apply(dict, 2, as.numeric)
dict<-scale(dict)
dict<-dict[-555,]
# TF-IDF weighting
tfidf<-read.csv("Dictionary_Scores_tfidf.csv", header=FALSE)
tfidf<-t(tfidf)
tfidf<-scale(tfidf)
# Date of the speeches
date<-read.csv("dates.csv", header=FALSE)
date<-t(date)[,1]
date<-as.Date(date, "%d/%m/%Y")
date<-read.csv("dates.csv", header=FALSE)
head(date)
rp <- read.csv("Risk_Premium.csv", sep="")
# function that returns the risk premium of the days of the speeches
GetTarget<-function(data, country, date){
}
GetTarget<-function(data, country, date){
# spread
rp1<-data$values[rp$geo==country] - data$values[rp$geo=="DE"]
# date of risk premium
date1<-data[data$geo==country,3]
# combine spread and date in data.frame
X<-data.frame(time=date1, spread=rp1)
X$time<-as.Date(X$time, "%Y-%m-%d")
X<-X[X$time>"1998-01-1",]
# find index of dates
index<-rep(NA,length(date))
for( i in 1:length(index)){
if(date[i] %in% X$time){
ind<-which(X$time==date[i])
ind2<-which(!is.na(X$spread[ind:(ind+10)])==TRUE)[1]
#index[i]<-which(X$time==date[i])
index[i]<-ind+ind2-1
} else {
ind<-which(X$time %in% c(date[i]+1,date[i]+2, date[i]+3,date[i]+4, date[i]+5))[1]
ind2<-which(!is.na(X$spread[ind:(ind+10)])==TRUE)[1]
#index[i]<-which(X$time %in% c(date[i]+1,date[i]+2, date[i]+3,date[i]+4, date[i]+5))[1]
index[i]<-ind+ind2-1
}
}
# fill target
target<-rep(NA,length(date))
for( i in 1:length(target)){
target[i]<-X$spread[index[i]]
}
return(list(target=target, index=index, X=X))
}
Result<-GetTarget(rp, "ES", date)
function (x, arr.ind = FALSE, useNames = TRUE)
Result<-GetTarget(rp, "ES", date)
date<-read.csv("dates.csv", header=FALSE)
date<-t(date)[,1]
date<-as.Date(date, "%d/%m/%Y")
Result<-GetTarget(rp, "ES", date)
index<-Result$index
X<-Result$X
target<-Result$target
target<-target[-555]
target<-log(target+1)
# Data preparation
X<-cbind(lda, dict, tfidf)
dict_names<-c("Negative", "Positive", "Uncertainty", "Litigious", "Constraining", "Superfluous","Interesting", "Harvard_IV")
colnames(X)[1:20]<-paste("Topic_", 1:20, sep="")
colnames(X)[21:28]<-dict_names
colnames(X)[29:36]<-paste("tfidf_", dict_names, sep="")
# Model
model<-lm(target ~. , data=X[,-1])
summary(model)
# Stepwise Regression
library(MASS)
stepwise <- stepAIC(model, direction="both")
stepwise$anova # display results
model_step<-lm(target ~ Topic_5 + Topic_8 + Topic_9 + Topic_10 + Topic_11 +
Topic_12 + Topic_14 + Topic_17 + Topic_20 + Positive + Litigious +
Constraining + tfidf_Negative + tfidf_Harvard_IV, data=X[,-c(1,23)])
summary(model_step) # 13 variables
# Variable Selection with Leaps Package
library(leaps)
leaps<-regsubsets(target~. ,data=X[,-1],nbest=1)
summary(leaps)
# best leaps model
model_leaps<-lm(target ~ Topic_5 + Topic_10 + Topic_11 + Topic_14 + Topic_20 + Positive + tfidf_Negative +tfidf_Harvard_IV, data=X[,-1])
summary(model_leaps)
### PLOTS
# Topic
topic<-apply(lda,1,which.max)
topic_score<-apply(lda,1,max)
topic_top<-topic[461]
topic_top
# Plot LDA scores
#png("/home/yaroslav/Dropbox/BGSE/3rd Term/Text Mining/Project/document/lda.png", width = 400, height = 350)
par(mfrow=c(3,2))
for( i in c(5,6,10,11,14,20)){  #4
plot(date[-555],lda[,i], t="h", main=paste("Topic",i), ylab="",xlab="",col="darkblue")
grid()
}
#dev.off()
# Plot Dictionary scores
#png("/home/yaroslav/Dropbox/BGSE/3rd Term/Text Mining/Project/document/dict_1.png", width = 400, height = 350)
par(mfrow=c(2,2))
for( i in 1:4){
plot(date[-555],dict[,i], t="h", main=dict_names[i], col="darkblue", xlab="", ylab="")
grid()
}
#dev.off()
#png("/home/yaroslav/Dropbox/BGSE/3rd Term/Text Mining/Project/document/dict_2.png", width = 400, height = 350)
par(mfrow=c(2,2))
for( i in 5:8){
plot(date[-555],dict[,i], t="h", main=dict_names[i], col="darkblue", xlab="", ylab="")
grid()
}
#dev.off()
# Plot risk premium
date_rp<-as.Date(rp$time[rp$geo=="ES"], "%Y-%m-%d")
rp_es<-rp$values[rp$geo=="ES"] - rp$values[rp$geo=="DE"]
ok<-4000:9503 # plot since 1995
par(mfrow=c(1,1))
#png("/home/yaroslav/Dropbox/BGSE/3rd Term/Text Mining/Project/document/risk_premium.png", width = 380, height = 300)
plot(date_rp[ok], rp_es[ok], t="l", main="Spain's risk premium",
col="darkblue", ylab="", xlab ="", lwd=1.2)
grid()
abline(v=as.Date("2012-27-07", "%Y-%d-%m"), lty=2, lwd=1.8)
#dev.off()
# md tables of models for the paper
library(pander)
pandoc.table(round(summary(model_step)$coefficients,3))
pandoc.table(round(summary(model_leaps)$coefficients,3))
